{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9f32bcfd-8a9f-448b-816c-092c7d2f1269",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "# Curated Data - Data for R Pipeline\n",
    " \n",
    "**Description** This notebook creates the curated for Aortic Stenosis, SAVR and TAVI.\n",
    " \n",
    "**Authors** Fionna Chalmers, Anna Stevenson (Health Data Science Team, BHF Data Science Centre)\n",
    "\n",
    "**Reviewers** âš  UNREVIEWED\n",
    "\n",
    "**Notes** Note that TAVI code combinatons contain SAVR codes thus to derive a SAVR case, it must be established that a TAVI combination does not exist.\n",
    "\n",
    "**Data Output**\n",
    "- **`ccu056_out_codelists_inclusionsd`** : codelist for AS, SAVR and TAVI\n",
    "\n",
    "\n",
    "**Data Output**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1b05d82a-5054-4664-8552-291df83a181e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# 0. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "02d7c019-b288-4ab2-9fa3-66c509552cfb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# pyspark libraries\n",
    "import pyspark.sql.functions as f\n",
    "import pyspark.sql.types as t\n",
    "from pyspark.sql import Window\n",
    "\n",
    "from functools import reduce\n",
    "\n",
    "import databricks.koalas as ks\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import re\n",
    "import io\n",
    "import datetime\n",
    "\n",
    "# plotting libraries\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import dates as mdates\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# versions\n",
    "print(\"Matplotlib version: \", matplotlib.__version__)\n",
    "print(\"Seaborn version: \", sns.__version__)\n",
    "_datetimenow = datetime.datetime.now() # .strftime(\"%Y%m%d\")\n",
    "print(f\"_datetimenow:  {_datetimenow}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5a166e7e-431a-40aa-8bff-d844ed75e204",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##0.1 Helpers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "acfaf985-89c2-4c6f-bfd3-8f118262310e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Common Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3eaa2f04-bc1d-4be4-85cc-6de023840a26",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run \"/Repos/shds/common/functions\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "89d1a9c4-97e7-4dbb-8fe4-907b955c3b83",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Help Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0cc18f5d-0ab4-4af5-99e3-62910350500f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run \"/Repos/shds/Fionna/help_functions\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e7bec103-5562-433a-a5a1-0201df7d968e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##0.2 Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b4a6415e-d5ad-4b12-993a-04cc50e91472",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%run \"./CCU056-01-parameters\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0cf77416-3476-4a82-ba92-863cefb97148",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##0.3 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "76898753-8a62-4015-abc2-fa390f91e885",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "hes_apc_long = spark.table(f'{dsa}.{proj}_cur_hes_apc_all_years_archive_long')\n",
    "hes_apc_op_long = spark.table(f'{dsa}.{proj}_cur_hes_apc_all_years_archive_op_long')\n",
    "hes_apc_op_otr_long = spark.table(f'{dsa}.{proj}_cur_hes_apc_all_years_archive_op_otr_long')\n",
    "codelists_inclusions = spark.table(f'{dsa}.{proj}_out_codelists_inclusions')\n",
    "\n",
    "skinny_unassembled = spark.table(f'{dsa}.{proj}_tmp_kpc_harmonised')\n",
    "skinny_assembled = spark.table(f'{dsa}.{proj}_tmp_skinny')\n",
    "lsoa = spark.table(f'{dsa}.{proj}_lsoa')\n",
    "\n",
    "acs   = extract_batch_from_archive(parameters_df_datasets, 'nacsa')\n",
    "tavi = extract_batch_from_archive(parameters_df_datasets, 'tavi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "33a37186-194e-42f2-9ac5-660b74d08ead",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(codelists_inclusions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "75140246-cccc-4908-943c-1c136c249d87",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# 1. HES APC - Aortic Stenosis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b90aa0db-5bf2-4ee7-98d7-01bd2dafc9e0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##Check\n",
    "\n",
    "Just checking no instances in which a 3 digit code is present but the 4 digit is missing, as when we filter for out codelist we use the 4 digits.\n",
    "\n",
    "Only 9 cases found and they do not apply to our project codelists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "88f3b272-0e58-4b85-8e21-e1c29163deea",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# hes_apc_op_long = spark.table(f'{dsa}.{proj}_cur_hes_apc_all_years_archive_op_long')\n",
    "\n",
    "# hes_op_wide = (hes_apc_op_long.groupBy(\"PERSON_ID\",\"EPIKEY\",\"EPISTART\",\"ADMIDATE\",\"OPERTN_POSITION\").pivot(\"OPERTN_DIGITS\").agg(f.first(\"CODE\")))\n",
    "\n",
    "# tmp1 = (\n",
    "#     hes_op_wide\n",
    "#     .withColumnRenamed('3','OPERTRN_3').withColumnRenamed('4','OPERTRN_4')\n",
    "#     .withColumn(\"OPERTRN_4_3\", f.col(\"OPERTRN_4\").substr(1, 3))\n",
    "#     .withColumn(\"check\", f.when(f.col(\"OPERTRN_4_3\")==f.col(\"OPERTRN_3\"), 1).otherwise(0))\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bdbb56c4-9069-4683-bf67-818737e0679c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# display(tmp1.groupBy(\"check\").count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d651fb0d-f2cf-4b7c-9eb4-cbf92d8698ad",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# display(tmp1.filter(f.col(\"check\")==0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "41e3a61b-3072-4a0c-9b14-3d666033d4ee",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    " as_codes = (\n",
    "     hes_apc_long\n",
    "     .join((codelists_inclusions.filter(f.col(\"name\")==\"aortic_stenosis\").select(f.col(\"code\").alias(\"CODE\"))),\n",
    "           on=\"CODE\",how=\"inner\")\n",
    " )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "392e42af-d085-4304-8ea7-2e87ba617bd3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(as_codes.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d7f0f580-fdbe-4346-ad5b-6c148a578ba0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(as_codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3e2991dd-c718-4827-8a1e-29006c67c23e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "save_table(df=as_codes,out_name=f'{proj}_tmp_cases_as_codes', save_previous=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1ba6d999-91f5-4531-ae0d-552cca0ae2f0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# 2. HES APC - Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fc5808c6-36b4-41a5-8808-f6a4975bd9af",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "procedure_codes = (\n",
    "     hes_apc_op_long\n",
    "     .join((codelists_inclusions.filter(f.col(\"name\").isin(\"savr\",\"tavi\")).select(f.col(\"code\").alias(\"CODE\")).distinct()),\n",
    "           on=\"CODE\",how=\"inner\")\n",
    " )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4333c1ef-2811-4567-ad1c-ef2723933908",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(procedure_codes.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ee29d9d2-1a1b-429d-a266-3c918afe3add",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(procedure_codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "16b1591a-6f5d-4d51-81d5-59e573d1374a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "save_table(df=procedure_codes,out_name=f'{proj}_tmp_cases_procedure_codes', save_previous=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "86ac5628-d4ba-46b2-8d77-766a4798088f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##2.1 Operation Dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6ad63b00-9690-4b58-ae52-55b1d6643d11",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "hes_apc_op_otr_long_cohort = (\n",
    "     hes_apc_op_otr_long\n",
    "     .withColumnRenamed('OPERTN','CODE')\n",
    "     .join((codelists_inclusions.filter(f.col(\"name\").isin(\"savr\",\"tavi\")).select(f.col(\"code\").alias(\"CODE\")).distinct()),\n",
    "           on=\"CODE\",how=\"inner\")\n",
    " )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f42ec6d8-0d48-4e51-853f-7138cd5ba9a6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(hes_apc_op_otr_long_cohort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6a3f94fc-f678-4ef5-90ea-8c3e49f88b64",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "save_table(df=hes_apc_op_otr_long_cohort,out_name=f'{proj}_tmp_cases_procedure_codes_operation_dates', save_previous=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "439c05df-9ae7-4f69-b05c-398dd4887ece",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#3. Audits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aa237544-7379-464c-a0fe-3b5d7b27a5a6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "save_table(df=acs,out_name=f'{proj}_tmp_cases_acs', save_previous=False)\n",
    "save_table(df=tavi,out_name=f'{proj}_tmp_cases_tavi', save_previous=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9f6b3960-70c0-4739-8018-a6e7ae004759",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f4140832-0593-498f-a3d6-89b23f6baa11",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "Skinny selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "693ec4c5-fd12-4945-9e57-d34220e2753c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#unassembled dummy data\n",
    "\n",
    "dummy = skinny_unassembled.filter(f.col(\"PERSON_ID\").isin([\"000K1P6P6B5FXHH\",\"00GSM26FLPY83DM\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0db2948a-382d-4345-94bf-b52e90fec0ee",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(skinny.filter(f.col(\"PERSON_ID\").isin([\"000K1P6P6B5FXHH\",\"00GSM26FLPY83DM\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a3e2e244-cdb7-4f78-9cdd-54c0d8e279b9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "24079b35-7690-4227-97e0-3702d2d62f72",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "  \"\"\"\n",
    "  Description:\n",
    "    Function to produce the project-specific patient skinny assembled table, as per DATA_CURATION\\\\curr302_patient_skinny_record:\n",
    "      **Description** Making a single record for each patient in primary and secondary care.\n",
    "      **Author(s)** Sam Hollings\n",
    "      **Reviewer(s)** Angela Wood\n",
    "\n",
    "  Args:\n",
    "    _unassembled (DataFrame): A dataframe containing the patient skinny unassembled table produced by the skinny_unassembled function.\n",
    "    _overall_censor_date (str): A date string (e.g., '2020-01-01') containing the overall censor date used to exclude records before assembling. \n",
    "    _individual_censor_dates (DataFrame): A dataframe containing individual censor dates used to exclude records before assembling. \n",
    "    _prioritise_primary_care (bool): A boolean indicating whether to prioritise primary care records when assembling (default = True).\n",
    "    \n",
    "  Returns:\n",
    "    pyspark.sql.DataFrame: A dataframe containing the patient skinny record.\n",
    "    \n",
    "  Example:\n",
    "    ...    \n",
    "  \"\"\"   \n",
    "  \n",
    "  \n",
    "  # ------------------------------------------------------------------------------------\n",
    "  # dss_corporate\n",
    "  # ------------------------------------------------------------------------------------    \n",
    "  ethnic_hes = spark.table(f'dss_corporate.hesf_ethnicity')\n",
    "  ethnic_gdppr = spark.table(f'dss_corporate.gdppr_ethnicity')\n",
    "  \n",
    "  \n",
    "  \n",
    "  varlist = ['DOB', 'SEX', 'ETHNIC']\n",
    "      \n",
    "  # remove those with missing ID, missing record date, and record date in the future  \n",
    "  _harmonised = (\n",
    "    harmonised\n",
    "    .where(f.col('PERSON_ID').isNotNull())\n",
    "    .where(f.col('RECORD_DATE').isNotNull())\n",
    "    .where(f.col('RECORD_DATE') <= f.col('archived_on')))\n",
    "  \n",
    "  # ------------------------------------------------------------------------------------\n",
    "  # _prioritise_primary_care\n",
    "  # ------------------------------------------------------------------------------------       \n",
    "  assert prioritise_primary_care in [0, 1]\n",
    "  if(prioritise_primary_care == 0):\n",
    "    # if zero (no) then null the RECORD_PRIMARY column\n",
    "    # note: this edit avoids having to redefine windows later\n",
    "    print(f'** NOT prioritising primary care records **')\n",
    "    _harmonised = (_harmonised.withColumn('RECORD_PRIMARY', f.lit(None))) \n",
    "  else: print(f'** prioritising primary care records **')\n",
    "  \n",
    "  # ------------------------------------------------------------------------------------\n",
    "  # characteristic selection preparation\n",
    "  # ------------------------------------------------------------------------------------ \n",
    "  # define RECORD_PRIMARY_DOB, ensure HES APC is prioritised above HES AE and HES OP (which are based on an estimate using age)\n",
    "  # define RECORD_SOURCEn\n",
    "  _harmonised = (\n",
    "    _harmonised\n",
    "    .withColumn('RECORD_PRIMARY_DOB',\n",
    "      f.when(f.col('RECORD_SOURCE').isin(['hes_ae', 'hes_op']), -1)\n",
    "      .otherwise(f.col('RECORD_PRIMARY'))\n",
    "    )\n",
    "    .withColumn('RECORD_SOURCEn',\n",
    "      f.when(f.col('RECORD_SOURCE') == 'gdppr', 1)\n",
    "      .when(f.col('RECORD_SOURCE') == 'gdppr_snomed', 2)\n",
    "      .when(f.col('RECORD_SOURCE') == 'hes_apc', 3)\n",
    "      .when(f.col('RECORD_SOURCE') == 'hes_op', 4)\n",
    "      .when(f.col('RECORD_SOURCE') == 'hes_ae', 5)\n",
    "    ))\n",
    "\n",
    "  # checks turned off for runtime\n",
    "  # assert _unassembled.count() == _unassembled.where(f.col('RECORD_SOURCEn').isNotNull()).count()\n",
    "  \n",
    "  # define windows for row numbers\n",
    "  _win_rownum_DOB = (\n",
    "    Window\n",
    "    .partitionBy('PERSON_ID')\\\n",
    "    .orderBy(['DOB_null', f.desc('RECORD_PRIMARY_DOB'), f.desc('RECORD_DATE'), 'RECORD_SOURCEn', 'RECORD_ID']))\n",
    "  _win_rownum_SEX = (\n",
    "    Window\n",
    "    .partitionBy('PERSON_ID')\n",
    "    .orderBy(['SEX_null', f.desc('RECORD_PRIMARY'), f.desc('RECORD_DATE'), 'RECORD_SOURCEn', 'RECORD_ID']))\n",
    "  _win_rownum_ETHNIC = (\n",
    "    Window\n",
    "    .partitionBy('PERSON_ID')\n",
    "    .orderBy(['ETHNIC_null', f.desc('RECORD_PRIMARY'), f.desc('RECORD_DATE'), 'RECORD_SOURCEn', 'RECORD_ID']))\n",
    "  \n",
    "  # create null indicators\n",
    "  # add row numbers\n",
    "  _harmonised = (\n",
    "    _harmonised\n",
    "    .withColumn('DOB_null',\n",
    "      f.when(\n",
    "        (f.col('DOB').isNull())\n",
    "        | (f.trim(f.col('DOB')).isin(['']))\n",
    "        | (f.col('DOB') < '1900-01-01')\n",
    "        | (f.col('DOB') > f.col('archived_on'))\n",
    "        | (f.col('DOB') > f.col('RECORD_DATE'))\n",
    "      , 1).otherwise(0)\n",
    "    )\n",
    "    .withColumn('SEX_null',\n",
    "      f.when( (f.col('SEX').isNull()) | (f.trim(f.col('SEX')).isin(['', '9', '0'])), 1).otherwise(0)\n",
    "    )\n",
    "    .withColumn('ETHNIC_null',\n",
    "      f.when( (f.col('ETHNIC').isNull()) | (f.trim(f.col('ETHNIC')).isin(['', '9', '99', 'X', 'Z'])), 1).otherwise(0)\n",
    "    )\n",
    "    .withColumn('_rownum_DOB', f.row_number().over(_win_rownum_DOB))\n",
    "    .withColumn('_rownum_SEX', f.row_number().over(_win_rownum_SEX))\n",
    "    .withColumn('_rownum_ETHNIC', f.row_number().over(_win_rownum_ETHNIC)))\n",
    "  \n",
    "  # ------------------------------------------------------------------------------------\n",
    "  # ties\n",
    "  # ------------------------------------------------------------------------------------   \n",
    "  # create indicators for tied records that have different values for a given variable  \n",
    "  for ind, var in enumerate(varlist):\n",
    "    # define window for tied records\n",
    "    record_primary = 'RECORD_PRIMARY'\n",
    "    if(var == 'DOB'): record_primary = 'RECORD_PRIMARY_DOB'\n",
    "    _win_tie = Window\\\n",
    "      .partitionBy('PERSON_ID')\\\n",
    "      .orderBy(f'{var}_null', f.desc(record_primary), f.desc('RECORD_DATE'))\n",
    "      \n",
    "    # count distinct values of var (including null) within tied records\n",
    "    _tie = (\n",
    "      _harmonised\n",
    "      .withColumn(f'_tie_{var}', f.dense_rank().over(_win_tie))\n",
    "      .where(f.col(f'_tie_{var}') == 1)\n",
    "      .groupBy('PERSON_ID')\n",
    "      .agg(\n",
    "        f.countDistinct(f.col(f'{var}')).alias(f'_n_distinct_{var}')\n",
    "        , f.countDistinct(f.when(f.col(f'{var}').isNull(), 1)).alias(f'_null_{var}')\n",
    "      )\n",
    "      .withColumn(f'_tie_{var}', f.when((f.col(f'_n_distinct_{var}') + f.col(f'_null_{var}')) > 1, 1).otherwise(0))\n",
    "      .select('PERSON_ID', f'_tie_{var}'))\n",
    "  \n",
    "    if(ind == 0): _tmp_ties = _tie\n",
    "    else: _tmp_ties = (_tmp_ties.join(_tie, on=['PERSON_ID'], how='outer'))\n",
    "    \n",
    "  # ------------------------------------------------------------------------------------\n",
    "  # characteristic selection\n",
    "  # ------------------------------------------------------------------------------------       \n",
    "  # take information from the first row identified above\n",
    "  _tmp_selected = {}\n",
    "  for var in varlist:\n",
    "    _tmp = (\n",
    "      _harmonised\n",
    "      .select('PERSON_ID', 'RECORD_DATE', 'RECORD_SOURCE', f'{var}', f'_rownum_{var}')\n",
    "      .where(f.col(f'_rownum_{var}') == 1)\n",
    "      .withColumnRenamed('RECORD_DATE', f'_date_{var}')\n",
    "      .withColumnRenamed('RECORD_SOURCE', f'_source_{var}')\n",
    "      .select('PERSON_ID', f'{var}', f'_date_{var}', f'_source_{var}'))\n",
    "    _tmp_selected[f'{var}'] = _tmp\n",
    "  \n",
    "  # ------------------------------------------------------------------------------------  \n",
    "  # gdppr presence\n",
    "  # ------------------------------------------------------------------------------------  \n",
    "  # in_gdppr is extracted from the unfiltered table\n",
    "  #   so in_gdppr may relate to records after date exclusions\n",
    "  _tmp_in_gdppr = (\n",
    "    harmonised\n",
    "    .where(f.col('RECORD_SOURCE') == 'gdppr')\n",
    "    .select('PERSON_ID')\n",
    "    .distinct()\n",
    "    .where(f.col('PERSON_ID').isNotNull())\n",
    "    .withColumn('in_gdppr', f.lit(1)))  \n",
    "  \n",
    "  # ------------------------------------------------------------------------------------ \n",
    "  # ethnic lookup\n",
    "  # ------------------------------------------------------------------------------------ \n",
    "  # ethnic_hes\n",
    "  ethnic_hes = (\n",
    "    ethnic_hes\n",
    "    .select('ETHNICITY_CODE', 'ETHNICITY_DESCRIPTION')\n",
    "    .withColumnRenamed('ETHNICITY_CODE', 'ETHNIC')\n",
    "    .withColumnRenamed('ETHNICITY_DESCRIPTION', 'ETHNIC_DESC_HES'))\n",
    "\n",
    "  #  ethnic_gdppr\n",
    "  ethnic_gdppr = (\n",
    "    ethnic_gdppr\n",
    "    .select('Value', 'Label')\n",
    "    .withColumnRenamed('Value', 'ETHNIC')\n",
    "    .withColumnRenamed('Label', 'ETHNIC_DESC_GDPPR'))\n",
    "\n",
    "  # checks\n",
    "  assert ethnic_hes.count() == ethnic_hes.select('ETHNIC').distinct().count()\\\n",
    "    , \"ethnic_hes is not well-defined\"\n",
    "  vallist = list(range(0, 10)) + list('ABCDEFGHJKLMNPRSXZ')\n",
    "  tmp = (ethnic_hes.withColumn('chk', f.when(f.col('ETHNIC').isin(vallist), 1).otherwise(0)))\n",
    "  assert tmp.count() == tmp.where(f.col('chk') == 1).count()\\\n",
    "    , \"ethnic_hes does not have all required values defined\"\n",
    "  assert ethnic_gdppr.count() == ethnic_gdppr.select('ETHNIC').distinct().count()\\\n",
    "    , \"ethnic_gdppr is not well-defined\"\n",
    "  vallist = list('ABCDEFGHJKLMNPRSTWZ')\n",
    "  tmp = (ethnic_gdppr.withColumn('chk', f.when(f.col('ETHNIC').isin(vallist), 1).otherwise(0)))\n",
    "  assert tmp.count() == tmp.where(f.col('chk') == 1).count()\\\n",
    "    , \"ethnic_gdppr does not have all required values defined\"\n",
    "\n",
    "  # combine\n",
    "  ethnic = (\n",
    "    ethnic_hes\n",
    "    .join(ethnic_gdppr, on='ETHNIC', how='outer')\n",
    "    .withColumn('ETHNIC_DESC', f.coalesce(f.col('ETHNIC_DESC_HES'), f.col('ETHNIC_DESC_GDPPR')))\n",
    "    .orderBy('ETHNIC'))\n",
    "\n",
    "  # add ethnic cat\n",
    "  _tmp_ethnic = (\n",
    "    ethnic\n",
    "    .select('ETHNIC', 'ETHNIC_DESC')\n",
    "    .withColumn('ETHNIC_CAT',\n",
    "     f.when(f.col('ETHNIC').isin(['0','A','B','C']), f.lit('White'))\n",
    "      .when(f.col('ETHNIC').isin(['1','2','3','N','M','P']), f.lit('Black or Black British'))\n",
    "      .when(f.col('ETHNIC').isin(['4','5','6','L','K','J','H']), f.lit('Asian or Asian British'))\n",
    "      .when(f.col('ETHNIC').isin(['D','E','F','G']), f.lit('Mixed'))\n",
    "      .when(f.col('ETHNIC').isin(['7','8','W','T','S','R']), f.lit('Other'))\n",
    "      .when(f.col('ETHNIC').isin(['9','Z','X']), f.lit('Unknown'))\n",
    "      .otherwise('Unknown')\n",
    "    ))\n",
    "\n",
    "  # check\n",
    "  # tmpt = tab(ethnic_cat, 'ETHNIC_DESC', 'ETHNIC_CAT', var2_unstyled=1); print()\n",
    "    \n",
    "  # ------------------------------------------------------------------------------------  \n",
    "  # _selected\n",
    "  # ------------------------------------------------------------------------------------  \n",
    "  _selected = (\n",
    "    _tmp_selected['DOB']\n",
    "    .join(_tmp_selected['SEX'], on=['PERSON_ID'], how='outer')\n",
    "    .join(_tmp_selected['ETHNIC'], on=['PERSON_ID'], how='outer')\n",
    "    .join(_tmp_in_gdppr, on=['PERSON_ID'], how='outer')\n",
    "    .join(_tmp_ties, on=['PERSON_ID'], how='outer')\n",
    "    .join(_tmp_ethnic, on=['ETHNIC'], how='left')\n",
    "    .select('PERSON_ID', 'DOB', 'SEX', 'ETHNIC', 'ETHNIC_DESC', 'ETHNIC_CAT'\n",
    "            , '_date_DOB', '_source_DOB', '_tie_DOB'\n",
    "            , '_date_SEX', '_source_SEX', '_tie_SEX'\n",
    "            , '_date_ETHNIC', '_source_ETHNIC', '_tie_ETHNIC'\n",
    "            , 'in_gdppr'))\n",
    "\n",
    "  return _selected"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "CCU056-03e-curated_data_cases",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}